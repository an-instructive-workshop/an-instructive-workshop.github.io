---
layout: default3
title: home
permalink: /2025
title: Workshop Proposal 2025
nav: false
---


### Introduction
<br>
Post-training methods such as instruction fine-tuning and reinforcement learning from human feedback (RLHF) are critical in unlocking the potential of pre-trained foundation models, enabling them to follow complex instructions and perform a wide range of real-world tasks. For instance, posttraining methods have transformed base language models like GPT-3 into the phenomenal ChatGPT, and adapted models across different modalities like CLIP and Llama into vision-enhanced language models.

Despite significant advancements in post-training research, non-trivial gaps persist between closed
proprietary models and open(-weight) models. __Due to the limited transparency surrounding proprietary models’ post-training processes, there is a pressing need for an open platform that fosters collaboration and discussion.__
Building on the success of our inaugural workshop at NeurIPS 2023, we propose a sequel at ICLR 2025 to
address the following questions:

* How can we close the gap between open and closed instruction-following models? What are the
key techniques that give closed models their edge?
* What are the latest breakthroughs in post-training, including advances in training algorithms, data
curation, improving model robustness and generalization, etc.?

In addition to the topics above, __this year we propose a special theme: harnessing synthetic data
in post-training.__ Given the high cost of obtaining high-quality human-annotated data, synthetic data
has emerged as an effective alternative for model post-training, as evidenced by research on Llama-3
and Qwen-2. While synthetic data reduces annotation costs and enhances performance, it also raises
concerns such as narrowing generative diversity and the risk of "model collapse". We aim to explore
the following questions at the workshop:

* What is the current best practice for leveraging synthetic data in post-training?
* Could synthetic data be used to augment or complement limited human annotations, and if so,
what strategies best combine these sources?
* What are the consequences (positive, neutral, and negative) of using synthetic data in post-training?
Can we establish theoretical frameworks to quantify such consequences and their trade-offs?

While the workshop will emphasize the key questions above, we welcome broader discussions and
paper submissions related to post-training and instruction-following models. Topics may include but
are not limited to (1) effective and reliable evaluation; (2) interpretability and analysis; (3) improving
models’ reasoning, mathematical, coding, and decision-making capabilities via post-training; and (4)
specific applications and use cases of instruction-following models.

<br>

### Confirmed Speakers

* [Chelsea Finn](https://ai.stanford.edu/%7Ecbfinn/), Stanford University, Physical Intelligence
* [Danqi Chen](https://www.cs.princeton.edu/%7Edanqic/), Princeton University
* [Eric Wallace](https://www.ericswallace.com/), OpenAI
* [Yarin Gal](https://www.cs.ox.ac.uk/people/yarin.gal/website/), University of Oxford, UK Government’s AI Safety Institute
* [Holy Lovenia](https://holylovenia.github.io/), AI Singapore

<br>
### Confirmed Panelists

* [Danqi Chen](https://www.cs.princeton.edu/%7Edanqic/), Princeton University
* [Eric Wallace](https://www.ericswallace.com/), OpenAI
* [Yarin Gal](https://www.cs.ox.ac.uk/people/yarin.gal/website/), University of Oxford, UK Government’s AI Safety Institute
* [Bill Yuchen Lin](https://yuchenlin.xyz/), Allen Institute for AI
* [Graham Neubig](https://www.phontron.com/), Carnegie Mellon University


<br>

### Confirmed Reviewers
* Lj Miranda, Allen Institute for AI
* Bowen Zhao, University of Washington
* Hamish Ivison, Allen Institute for AI
* Shane Lyu, Allen Institute for AI
* Mickel Liu, Allen Institute for AI
* Harvey Yiyun Fu, University of Southern California
* Ting-Yun Chang, University of Southern California
* Mozhdeh Gheini, University of Southern California
* Huihan Li, University of Southern California
* Lorena Yan, University of Southern California
* Siyuan Wang, University of Southern California
* Xiaoyue Xu, Tsinghua University
* Zhankui He, Google
* Bowen Pan, Massachusetts Institute of Technology
* Taiwei Shi, University of Southern California
* Xingyao Wang, University of Illinois Urbana-Champaign
* Yu Wang, University of California, San Diego
* Seonghyeon Ye, Korea Advanced Institute of Science and Technology
* Lintang Sutawika, Eleuther AI & Carnegie Mellon University
* Sadhika Malladi, Princeton University
* Tianyu Gao, Princeton University
* Zhiyuan Zeng, Tsinghua University
* Dingli Yu, Princeton University
* Simran Kaur, Princeton University
* Christopher Klamm, University of Mannheim
* Will Brannon, Massachusetts Institute of Technology
* Da Yin, University of California, Los Angeles
* Jinheon Baek, Korea Advanced Institute of Science and Technology
* Sungdong Kim, Korea Advanced Institute of Science and Technology & NAVER Cloud
* Akari Asai, University of Washington
* Kartik Perisetla, Apple

<br>

### Organizers

* [Mengzhou Xia](https://xiamengzhou.github.io/), Princeton University
* [Zexue He](https://zexuehe.github.io/), University of California, San Diego
* [Seungone Kim](https://seungonekim.github.io/), Korea Advanced Institute of Science and Technology, Carnegie Mellon University
* [Qinyuan Ye](https://yeqy.xyz/), University of Southern California
* [Yizhong Wang](https://homes.cs.washington.edu/%7Eyizhongw/), University of Washington
* [Shayne Longpre](https://www.shaynelongpre.com/), Massachusetts Institute of Technology

<br>
<br>